{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratório: Fine-Tuning de LLMs para Instruction Following\n",
        "Configuração do ambiente e verificação de versões."
      ],
      "metadata": {
        "id": "2l94shYzDYEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydFbGMV2DThn",
        "outputId": "2769d642-7cb9-41fd-db40-91063c05f5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: llms-from-scratch in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.19.0)\n",
            "Requirement already satisfied: jupyterlab>=4.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (4.5.4)\n",
            "Requirement already satisfied: pip>=25.0.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (26.0.1)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (8.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.2.0)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.9.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.28.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.5.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.4.9)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.4)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.17.0)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.24.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (26.2.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.1.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.9.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.13.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (4.26.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.9.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.10.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.5.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.10.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.18.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.8.3)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (0.0.4)\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets pandas psutil requests tqdm tiktoken torch matplotlib llms-from-scratch\n",
        "\n",
        "from importlib.metadata import version\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "\n",
        "# Importações do repositório\n",
        "from llms_from_scratch.ch04 import GPTModel\n",
        "from llms_from_scratch.ch05 import (\n",
        "    download_and_load_gpt2,\n",
        "    load_weights_into_gpt,\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text,\n",
        "    plot_losses,\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "random.seed(123)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Construção do Dataset de Instruções\n",
        "Carregando o AG News, formatando para instruções"
      ],
      "metadata": {
        "id": "yrYoeHKMDfip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"ag_news\")\n",
        "df = pd.DataFrame(dataset['train']).sample(500, random_state=42)\n",
        "label_map = {0: \"Mundo\", 1: \"Esportes\", 2: \"Negócios\", 3: \"Ciência/Tecnologia\"}\n",
        "\n",
        "meu_dataset = []\n",
        "for _, row in df.iterrows():\n",
        "    if len(row['text']) > 50:\n",
        "        meu_dataset.append({\n",
        "            \"instruction\": \"Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.\",\n",
        "            \"input\": row['text'],\n",
        "            \"output\": label_map[row['label']]\n",
        "        })\n",
        "\n",
        "random.shuffle(meu_dataset)\n",
        "total = len(meu_dataset)\n",
        "train_data_pequeno = meu_dataset[:int(total * 0.8)]\n",
        "val_data = meu_dataset[int(total * 0.8):int(total * 0.9)]\n",
        "test_data = meu_dataset[int(total * 0.9):]\n",
        "\n",
        "print(f\"Treino Pequeno: {len(train_data_pequeno)} | Val: {len(val_data)} | Teste: {len(test_data)}\")\n",
        "\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Abaixo está uma instrução que descreve uma tarefa. \"\n",
        "        f\"Escreva uma resposta que conclua a solicitação adequadamente.\"\n",
        "        f\"\\n\\n### Instrução:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text = f\"\\n\\n### Entrada:\\n{entry['input']}\" if entry.get(\"input\") else \"\"\n",
        "    return instruction_text + input_text\n",
        "\n",
        "print(\"\\nExemplo formatado:\")\n",
        "print(format_input(train_data_pequeno[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSBPbPzsDgB7",
        "outputId": "9c0bf3d4-b244-4244-b0d5-782de67cab0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino Pequeno: 400 | Val: 50 | Teste: 50\n",
            "\n",
            "Exemplo formatado:\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.\n",
            "\n",
            "### Instrução:\n",
            "Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.\n",
            "\n",
            "### Entrada:\n",
            "I thought I saw a shove, but I guess I need glasses Nothing happened, Reggie Wayne said. Nothing happened when the Indianapolis Colts wide receiver and Peyton Manning went face mask to face mask on the sideline late in Sunday #39;s game.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparação dos DataLoaders (Analítico)\n",
        "Usando a custom_collate_fn do Cap 07 e verificando o formato dos tensores gerados para garantir que o padding e a máscara (-100) funcionem."
      ],
      "metadata": {
        "id": "avZHYSNEDmWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Resposta:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "    def __getitem__(self, index): return self.encoded_texts[index]\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [], []\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "    return torch.stack(inputs_lst).to(device), torch.stack(targets_lst).to(device)"
      ],
      "metadata": {
        "id": "ggh-EX9eciYD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Creating data loaders for an instruction dataset\n",
        "Instanciando os lotes e inspecionando visualmente as matrizes para garantir que o padding e a máscara (-100) foram aplicados com sucesso."
      ],
      "metadata": {
        "id": "OoiEP2KBrpQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=256)\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset_pequeno = InstructionDataset(train_data_pequeno, tokenizer)\n",
        "train_loader_pequeno = DataLoader(train_dataset_pequeno, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=True, drop_last=True)\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=False)\n",
        "\n",
        "print(\"Análise das dimensões do Train loader:\")\n",
        "for inputs, targets in train_loader_pequeno:\n",
        "    print(inputs.shape, targets.shape)\n",
        "    break\n",
        "\n",
        "inputs, targets = next(iter(train_loader_pequeno))\n",
        "print(\"\\nPrimeira matriz de Entrada (Inputs)\")\n",
        "print(inputs[0])\n",
        "print(\"\\nPrimeira matriz de Alvo (Targets)\")\n",
        "print(targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vByw2nmro0C",
        "outputId": "b9f1d662-18c4-49b2-b8a0-1819f227de6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Análise das dimensões do Train loader:\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "\n",
            "Primeira matriz de Entrada (Inputs)\n",
            "tensor([ 4826,    64,   844,    78,  1556,  6557,   334,  2611,   916,   622,\n",
            "        16175, 28749,  8358,  1715, 36955,   334,  2611,   256,   533, 13331,\n",
            "           13, 16319,   260,  6862,   334,  2611,  1217, 39818,  8358,   369,\n",
            "          565,  6413,   257, 25063,    64, 16175, 28749,  9939,   324,  3263,\n",
            "           68,    13,   198,   198, 21017,  2262,   622, 16175, 28749,    25,\n",
            "          198,  9487,   361,  2350,   267,  2420,    78, 12379,   407,  8836,\n",
            "        33743,   450,    64,   844,    78,   795,   334,  2611,   288,   292,\n",
            "          384,  5162,   600,   274, 17851,  4448,    25, 33324,    78,    11,\n",
            "         8678,   634,   274,    11, 13496, 10205,   979,   418,   267,    84,\n",
            "        37685, 25792, 10782,   544,    14,    51,   721,    77,   928,   544,\n",
            "           13,   198,   198, 21017,  7232,    81,  4763,    25,   198, 19100,\n",
            "           25,  6365, 36139,  6085,    12, 35969, 13468,    12,  6495,    11,\n",
            "         4167,  1222,  2528,    26,    65,     5, 13655,    26,   986,     5,\n",
            "         2528,    26,    14,    65,     5, 13655,    26,   383,  1743,  1705,\n",
            "         4086,   286,  6365,  1139,  2766,   612,   423,  4251,   281,  4547,\n",
            "          351,  2692,    11,   262, 12890,    11,   262,  1578,  1829,   290,\n",
            "         2031,    13,   198,   198, 21017,  1874,  7353,    64,    25,   198,\n",
            "           44, 41204, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256], device='cuda:0')\n",
            "\n",
            "Primeira matriz de Alvo (Targets)\n",
            "tensor([   64,   844,    78,  1556,  6557,   334,  2611,   916,   622, 16175,\n",
            "        28749,  8358,  1715, 36955,   334,  2611,   256,   533, 13331,    13,\n",
            "        16319,   260,  6862,   334,  2611,  1217, 39818,  8358,   369,   565,\n",
            "         6413,   257, 25063,    64, 16175, 28749,  9939,   324,  3263,    68,\n",
            "           13,   198,   198, 21017,  2262,   622, 16175, 28749,    25,   198,\n",
            "         9487,   361,  2350,   267,  2420,    78, 12379,   407,  8836, 33743,\n",
            "          450,    64,   844,    78,   795,   334,  2611,   288,   292,   384,\n",
            "         5162,   600,   274, 17851,  4448,    25, 33324,    78,    11,  8678,\n",
            "          634,   274,    11, 13496, 10205,   979,   418,   267,    84, 37685,\n",
            "        25792, 10782,   544,    14,    51,   721,    77,   928,   544,    13,\n",
            "          198,   198, 21017,  7232,    81,  4763,    25,   198, 19100,    25,\n",
            "         6365, 36139,  6085,    12, 35969, 13468,    12,  6495,    11,  4167,\n",
            "         1222,  2528,    26,    65,     5, 13655,    26,   986,     5,  2528,\n",
            "           26,    14,    65,     5, 13655,    26,   383,  1743,  1705,  4086,\n",
            "          286,  6365,  1139,  2766,   612,   423,  4251,   281,  4547,   351,\n",
            "         2692,    11,   262, 12890,    11,   262,  1578,  1829,   290,  2031,\n",
            "           13,   198,   198, 21017,  1874,  7353,    64,    25,   198,    44,\n",
            "        41204, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Avaliação Baseline (Modelo Não Treinado)\n",
        "Aqui geramos as respostas de controle. Como o modelo não viu o dataset estruturado, ele tende a repetir as instruções."
      ],
      "metadata": {
        "id": "3OI5lKe1Dqcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257, \"context_length\": 1024, \"drop_rate\": 0.0, \"qkv_bias\": True,\n",
        "    \"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16\n",
        "}\n",
        "settings, params = download_and_load_gpt2(model_size=\"355M\", models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Gerando respostas BASELINE (antes do Fine-Tuning)...\")\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "        model=model, idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=25, context_size=BASE_CONFIG[\"context_length\"], eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    test_data[i][\"model_base_response\"] = generated_text[len(input_text):].replace(\"### Resposta:\", \"\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOesV632DnN3",
        "outputId": "c78edeb8-46b3-4704-abdf-cc5098a10452"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [07:29<00:00, 3.16MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 10.4MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 666kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 446kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando respostas BASELINE (antes do Fine-Tuning)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:09<00:00,  1.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Treinamento Fine-Tuning (Dataset Pequeno) e Análise de Loss\n",
        "Cálculo da Initial Loss, seguido pelo treinamento do modelo e plotagem das curvas de perda."
      ],
      "metadata": {
        "id": "MzkC9wrPdEBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader_pequeno, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Perda Inicial (Training loss):\", train_loss)\n",
        "print(\"Perda Inicial (Validation loss):\", val_loss)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "num_epochs = 2\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"\\nIniciando Treinamento GPT-2 (Dataset Pequeno)...\")\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader_pequeno, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "print(f\"Treino concluído em {(time.time() - start_time) / 60:.2f} minutos.\")\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "t2-Qu833DpMH",
        "outputId": "d264c9a8-8749-4fec-daa4-af3af4e606d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perda Inicial (Training loss): 3.946356725692749\n",
            "Perda Inicial (Validation loss): 3.996236562728882\n",
            "\n",
            "Iniciando Treinamento GPT-2 (Dataset Pequeno)...\n",
            "Ep 1 (Step 000000): Train loss 3.049, Val loss 3.070\n",
            "Ep 1 (Step 000005): Train loss 1.196, Val loss 1.291\n",
            "Ep 1 (Step 000010): Train loss 1.029, Val loss 1.087\n",
            "Ep 1 (Step 000015): Train loss 1.006, Val loss 1.063\n",
            "Ep 1 (Step 000020): Train loss 0.967, Val loss 1.049\n",
            "Ep 1 (Step 000025): Train loss 0.932, Val loss 1.042\n",
            "Ep 1 (Step 000030): Train loss 0.948, Val loss 1.030\n",
            "Ep 1 (Step 000035): Train loss 0.864, Val loss 1.025\n",
            "Ep 1 (Step 000040): Train loss 0.851, Val loss 1.016\n",
            "Ep 1 (Step 000045): Train loss 0.816, Val loss 1.012\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.  ### Instrução: Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.  ### Entrada: Eagles' McDougle Has Irregular Heartbeat (AP) AP - Philadelphia defensive end Jerome McDougle missed practice Friday because of an irregular heartbeat and was doubtful for the Eagles' game this weekend against Cleveland.  ### Resposta: Esportes<|endoftext|>The following is a list of the most popular and most popular rated games on the PS3.  The following is a list of the most popular and most popular rated games on the PS\n",
            "Ep 2 (Step 000050): Train loss 0.788, Val loss 1.009\n",
            "Ep 2 (Step 000055): Train loss 0.716, Val loss 1.012\n",
            "Ep 2 (Step 000060): Train loss 0.724, Val loss 1.023\n",
            "Ep 2 (Step 000065): Train loss 0.701, Val loss 1.031\n",
            "Ep 2 (Step 000070): Train loss 0.790, Val loss 1.033\n",
            "Ep 2 (Step 000075): Train loss 0.684, Val loss 1.036\n",
            "Ep 2 (Step 000080): Train loss 0.621, Val loss 1.036\n",
            "Ep 2 (Step 000085): Train loss 0.642, Val loss 1.036\n",
            "Ep 2 (Step 000090): Train loss 0.596, Val loss 1.036\n",
            "Ep 2 (Step 000095): Train loss 0.625, Val loss 1.033\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.  ### Instrução: Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.  ### Entrada: Eagles' McDougle Has Irregular Heartbeat (AP) AP - Philadelphia defensive end Jerome McDougle missed practice Friday because of an irregular heartbeat and was doubtful for the Eagles' game this weekend against Cleveland.  ### Resposta: Esportes<|endoftext|>The following is a guest post by Michael J. Sullivan, a professor of history at the University of Minnesota.  In the late 1990s, the United States and its European allies began\n",
            "Treino concluído em 4.18 minutos.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Gerando as Respostas Pós-Treino e Salvando o Modelo\n",
        "Geração das respostas do modelo adaptado para comparativo com o Baseline."
      ],
      "metadata": {
        "id": "ikihUslyEQQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"--- Avaliação Visual (3 exemplos) ---\\n\")\n",
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Resposta:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "print(\"\\nA gerar respostas FINE-TUNED para todo o conjunto de teste...\")\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=25,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Resposta:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_ft_pequeno_response\"] = response_text\n",
        "\n",
        "# Guardar o JSON com as respostas\n",
        "with open(\"instruction-data-small-with-response.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(test_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Guardar os pesos do modelo treinado\n",
        "torch.save(model.state_dict(), \"gpt2-medium-ft-pequeno.pth\")\n",
        "\n",
        "print(\"\\nConcluído! Dados guardados em 'instruction-data-small-with-response.json'\")\n",
        "print(\"Pesos do modelo guardados em 'gpt2-medium-ft-pequeno.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffxhIxrIEJu6",
        "outputId": "a79bfdf4-26cd-4a5b-bc91-ecaaf48fa051"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Avaliação Visual (3 exemplos) ---\n",
            "\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.\n",
            "\n",
            "### Instrução:\n",
            "Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.\n",
            "\n",
            "### Entrada:\n",
            "Baseball-Backe Pitches Astros to 2-1 Series Lead  HOUSTON (Reuters) - Brandon Backe, a little-known local,  who arrived in the shadow of famous hometown heroes Roger  Clemens and Andy Pettitte last winter, brought the Houston  Astros to within a game of the franchise's first postseason  series victory in an 8-5 win over the Atlanta Braves Saturday.\n",
            "\n",
            "Correct response:\n",
            ">> Esportes\n",
            "\n",
            "Model response:\n",
            ">> Esportes\n",
            "-------------------------------------\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.\n",
            "\n",
            "### Instrução:\n",
            "Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.\n",
            "\n",
            "### Entrada:\n",
            "Ubiquitous browser hole an easy target for scammers Dec 10, 2004: A new web browser security hole has been uncovered by a security firm, which could provide scammers with the means to launch phishing attacks from pop-up windows on genuine, trusted websites.\n",
            "\n",
            "Correct response:\n",
            ">> Ciência/Tecnologia\n",
            "\n",
            "Model response:\n",
            ">> Ciência/Tecnologia\n",
            "-------------------------------------\n",
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua a solicitação adequadamente.\n",
            "\n",
            "### Instrução:\n",
            "Classifique o texto da notícia abaixo em uma das seguintes categorias: Mundo, Esportes, Negócios ou Ciência/Tecnologia.\n",
            "\n",
            "### Entrada:\n",
            "Iran Will Likely Freeze Nuke Enrichment-Official A senior Iranian official said on Thursday he was optimistic Iran would halt its uranium enrichment program as Europe demands, in a move aimed \n",
            "\n",
            "Correct response:\n",
            ">> Mundo\n",
            "\n",
            "Model response:\n",
            ">> Mundo\n",
            "-------------------------------------\n",
            "\n",
            "A gerar respostas FINE-TUNED para todo o conjunto de teste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:35<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Concluído! Dados guardados em 'instruction-data-small-with-response.json'\n",
            "Pesos do modelo guardados em 'gpt2-medium-ft-pequeno.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Setup do Juiz LLM: Liberação de Memória e Subida do Ollama\n",
        "Limpando a GPU e utilizando o Ollama local (Llama 3.2) para atuar como Juiz entre o modelo Baseline e o Fine-Tuned."
      ],
      "metadata": {
        "id": "72KePU4tFFiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y zstd\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Inicia o servidor do Ollama em segundo plano\n",
        "print(\"Iniciando o servidor Ollama...\")\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Aguarda uns segundos para o servidor inicializar completamente\n",
        "time.sleep(5)\n",
        "print(\"Servidor Ollama rodando no background!\")\n",
        "\n",
        "!ollama pull llama3.2"
      ],
      "metadata": {
        "id": "pCSq4Hk_EUdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62b91b8-811a-4f55-a5c5-574bb2cb539a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r            \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,361 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 https://cli.github.com/packages stable/main amd64 Packages [355 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,769 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,737 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,749 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,538 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,613 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,070 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,301 kB]\n",
            "Get:23 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,909 kB]\n",
            "Fetched 39.6 MB in 5s (7,871 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 603 kB of archives.\n",
            "After this operation, 1,695 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 zstd amd64 1.4.8+dfsg-3build1 [603 kB]\n",
            "Fetched 603 kB in 2s (352 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 121852 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
            "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Iniciando o servidor Ollama...\n",
            "Servidor Ollama rodando no background!\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ],
      "metadata": {
        "id": "4y7ZJrCjLWLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb46f8b-910f-4fdd-d66a-b17ad3faff0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# O comando nohup força o processo a rodar no background sem travar o Colab\n",
        "print(\"Iniciando o servidor Ollama em segundo plano...\")\n",
        "os.system(\"nohup ollama serve > ollama_server.log 2>&1 &\")\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"Servidor iniciado! Verificando os logs iniciais:\")\n",
        "# Exibe as primeiras linhas do log para confirmar que funcionou\n",
        "!cat ollama_server.log | head -n 5"
      ],
      "metadata": {
        "id": "C6fOsEugLYwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae009888-eb2c-4877-d079-4b37fa311048"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o servidor Ollama em segundo plano...\n",
            "Servidor iniciado! Verificando os logs iniciais:\n",
            "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Pipeline de Avaliação Final (LLM-as-a-Judge)"
      ],
      "metadata": {
        "id": "jVMnOL9Od0x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Evaluating the finetuned LLM\n",
        "Nesta secção, utilizamos o LLM-as-a-Judge (Llama 3.2 via Ollama local) para avaliar comparativamente o Modelo BASE (A) e o Modelo FINE-TUNED (B), conforme exigido no laboratório."
      ],
      "metadata": {
        "id": "EucfuySXMaWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "# 1. Limpeza para evitar OOM (Out of Memory)\n",
        "if 'model' in locals():\n",
        "    del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 2. Iniciar o Ollama (adaptado para o Colab não falhar)\n",
        "print(\"A iniciar o servidor Ollama...\")\n",
        "os.system(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "os.system(\"pkill ollama\")\n",
        "time.sleep(2)\n",
        "subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "time.sleep(5)\n",
        "print(\"A descarregar Llama 3.2...\")\n",
        "os.system(\"ollama pull llama3.2\")\n",
        "\n",
        "def query_model(prompt, model=\"llama3.2\", url=\"http://127.0.0.1:11434/api/chat\"):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "try:\n",
        "    print(\"\\nTeste de ligação:\", query_model(\"Responda apenas 'OK'.\"))\n",
        "except Exception as e:\n",
        "    print(f\"Erro na ligação ao Ollama: {e}\")"
      ],
      "metadata": {
        "id": "qb8-WPxSLiCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7fcc86-1dba-4a3b-c68c-096d139f0563"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A iniciar o servidor Ollama...\n",
            "A descarregar Llama 3.2...\n",
            "\n",
            "Teste de ligação: OK.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gerando as pontuações (Scoring)\n",
        "Criamos o *prompt* comparativo e avaliamos todas as entradas do conjunto de teste, extraindo as métricas utilizando expressões regulares (RegEx)."
      ],
      "metadata": {
        "id": "-gP6bEfhMgO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "prompt_template = \"\"\"Você é um juiz imparcial avaliando dois modelos de Inteligência Artificial em uma tarefa de classificação de texto.\n",
        "\n",
        "Instrução: {instrucao}\n",
        "Entrada: {entrada}\n",
        "Gabarito (Resposta Correta): {gabarito}\n",
        "\n",
        "Resposta Modelo A (Base): {resp_a}\n",
        "Resposta Modelo B (Fine-tuned): {resp_b}\n",
        "\n",
        "Avalie os dois modelos dando uma nota inteira de 0 a 5 para:\n",
        "1. Correção factual\n",
        "2. Aderência à instrução\n",
        "3. Clareza/utilidade\n",
        "\n",
        "Responda ESTRITAMENTE neste formato:\n",
        "Modelo A - Correção: [nota], Aderência: [nota], Clareza: [nota]\n",
        "Modelo B - Correção: [nota], Aderência: [nota], Clareza: [nota]\n",
        "Vencedor: [A, B ou Empate]\n",
        "Justificativa: [breve justificativa]\n",
        "\"\"\"\n",
        "\n",
        "resultados_avaliacao = []\n",
        "erros = 0\n",
        "\n",
        "print(\"A avaliar entradas do conjunto de teste...\")\n",
        "for entry in tqdm(test_data, desc=\"Scoring entries\"):\n",
        "    prompt = prompt_template.format(\n",
        "        instrucao=entry['instruction'],\n",
        "        entrada=entry.get('input', ''),\n",
        "        gabarito=entry['output'],\n",
        "        resp_a=entry.get('model_base_response', ''),\n",
        "        resp_b=entry.get('model_ft_pequeno_response', '')\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        judge_response = query_model(prompt)\n",
        "        entry['judge_evaluation'] = judge_response\n",
        "        resultados_avaliacao.append(entry)\n",
        "    except Exception as e:\n",
        "        erros += 1\n",
        "\n",
        "print(f\"\\nAvaliações concluídas. Falhas de conexão: {erros}\")"
      ],
      "metadata": {
        "id": "i_9RFe7lMkVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da6de5f-96d3-4a6e-9a9f-e623afd2da6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A avaliar entradas do conjunto de teste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring entries: 100%|██████████| 50/50 [05:45<00:00,  6.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Avaliações concluídas. Falhas de conexão: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculando as Médias e Exportando os Resultados\n",
        "Processamos o texto gerado pelo Juiz para calcular as vitórias e as pontuações médias de cada modelo."
      ],
      "metadata": {
        "id": "N81HMi1-Mm5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "vitorias = {'A': 0, 'B': 0, 'Empate': 0}\n",
        "scores_A = {'Correcao': [], 'Aderencia': [], 'Clareza': []}\n",
        "scores_B = {'Correcao': [], 'Aderencia': [], 'Clareza': []}\n",
        "\n",
        "falhas_parse = 0\n",
        "\n",
        "for entry in resultados_avaliacao:\n",
        "    eval_text = entry.get('judge_evaluation', '')\n",
        "\n",
        "    match_vencedor = re.search(r\"Vencedor\\s*[:\\*]*\\s*(?:Modelo\\s*)?([A-Za-z]+)\", eval_text, re.IGNORECASE)\n",
        "\n",
        "    match_A = re.search(r\"Modelo A.*?Corre[çc][ãa]o.*?(\\d).*?Ader[êe]ncia.*?(\\d).*?Clareza.*?(\\d)\", eval_text, re.IGNORECASE | re.DOTALL)\n",
        "    match_B = re.search(r\"Modelo B.*?Corre[çc][ãa]o.*?(\\d).*?Ader[êe]ncia.*?(\\d).*?Clareza.*?(\\d)\", eval_text, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    try:\n",
        "        # Verifica o Vencedor\n",
        "        if match_vencedor:\n",
        "            v = match_vencedor.group(1).upper()\n",
        "            if \"A\" in v: vitorias['A'] += 1\n",
        "            elif \"B\" in v: vitorias['B'] += 1\n",
        "            elif \"EMP\" in v or \"TIE\" in v: vitorias['Empate'] += 1\n",
        "            else: vitorias['Empate'] += 1\n",
        "\n",
        "        # Verifica as Notas\n",
        "        if match_A and match_B:\n",
        "            scores_A['Correcao'].append(int(match_A.group(1)))\n",
        "            scores_A['Aderencia'].append(int(match_A.group(2)))\n",
        "            scores_A['Clareza'].append(int(match_A.group(3)))\n",
        "\n",
        "            scores_B['Correcao'].append(int(match_B.group(1)))\n",
        "            scores_B['Aderencia'].append(int(match_B.group(2)))\n",
        "            scores_B['Clareza'].append(int(match_B.group(3)))\n",
        "        else:\n",
        "            falhas_parse += 1\n",
        "\n",
        "    except ValueError:\n",
        "        falhas_parse += 1\n",
        "\n",
        "# Impressão final ao estilo do Ch07\n",
        "total_avaliacoes = len(scores_A['Correcao'])\n",
        "\n",
        "print(f\"Number of scores parsed successfully: {total_avaliacoes} of {len(test_data)}\")\n",
        "if falhas_parse > 0:\n",
        "    print(f\"Failed to parse {falhas_parse} evaluations due to formatting issues.\")\n",
        "\n",
        "if total_avaliacoes > 0:\n",
        "    print(\"\\n--- WIN RATES ---\")\n",
        "    print(f\"Base Model (A) Wins:       {vitorias['A']} ({(vitorias['A']/total_avaliacoes)*100:.1f}%)\")\n",
        "    print(f\"Fine-Tuned Model (B) Wins: {vitorias['B']} ({(vitorias['B']/total_avaliacoes)*100:.1f}%)\")\n",
        "    print(f\"Ties (Empates):            {vitorias['Empate']} ({(vitorias['Empate']/total_avaliacoes)*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\n--- AVERAGE SCORES (0-5) ---\")\n",
        "    print(\"Base Model (A):\")\n",
        "    print(f\"  Correção:  {np.mean(scores_A['Correcao']):.2f}\")\n",
        "    print(f\"  Aderência: {np.mean(scores_A['Aderencia']):.2f}\")\n",
        "    print(f\"  Clareza:   {np.mean(scores_A['Clareza']):.2f}\")\n",
        "\n",
        "    print(\"\\nFine-Tuned Model (B):\")\n",
        "    print(f\"  Correção:  {np.mean(scores_B['Correcao']):.2f}\")\n",
        "    print(f\"  Aderência: {np.mean(scores_B['Aderencia']):.2f}\")\n",
        "    print(f\"  Clareza:   {np.mean(scores_B['Clareza']):.2f}\")\n",
        "\n",
        "# Atualiza o JSON com os dados consolidados\n",
        "with open(\"dataset_pequeno_avaliado_final.json\", \"w\", encoding='utf-8') as f:\n",
        "    json.dump(resultados_avaliacao, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "3x5zMYgrMn7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ce8973-208a-478f-9d5c-094deee5bba0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scores parsed successfully: 50 of 50\n",
            "\n",
            "--- WIN RATES ---\n",
            "Base Model (A) Wins:       2 (4.0%)\n",
            "Fine-Tuned Model (B) Wins: 46 (92.0%)\n",
            "Ties (Empates):            2 (4.0%)\n",
            "\n",
            "--- AVERAGE SCORES (0-5) ---\n",
            "Base Model (A):\n",
            "  Correção:  2.46\n",
            "  Aderência: 1.44\n",
            "  Clareza:   2.12\n",
            "\n",
            "Fine-Tuned Model (B):\n",
            "  Correção:  4.12\n",
            "  Aderência: 4.64\n",
            "  Clareza:   4.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_model_scores(json_data, json_key, model=\"llama3.2\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=f\"Scoring {json_key}\"):\n",
        "        prompt = (\n",
        "            f\"Dada a entrada `{format_input(entry)}` \"\n",
        "            f\"e a saída correta (gabarito) `{entry['output']}`, \"\n",
        "            f\"avalie a resposta do modelo `{entry.get(json_key, '')}` \"\n",
        "            f\"numa escala de 0 a 100, onde 100 é a nota máxima e 0 é a mínima. \"\n",
        "            f\"Responda APENAS com o número inteiro, sem textos adicionais.\"\n",
        "        )\n",
        "\n",
        "        score_text = query_model(prompt, model)\n",
        "\n",
        "        try:\n",
        "            # Tenta a conversão direta igual ao livro\n",
        "            score = int(score_text.strip())\n",
        "            scores.append(score)\n",
        "        except ValueError:\n",
        "            match = re.search(r\"(\\d+)\", score_text)\n",
        "            if match:\n",
        "                scores.append(int(match.group(1)))\n",
        "            else:\n",
        "                print(f\"\\nCould not convert score: {score_text}\")\n",
        "                continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "print(\"--- AVALIAÇÃO DE 0 A 100 (Estilo Capítulo 7) ---\")\n",
        "\n",
        "\n",
        "scores_ft = generate_model_scores(test_data, \"model_ft_pequeno_response\")\n",
        "\n",
        "print(f\"\\nResultados para o Modelo Fine-Tuned:\")\n",
        "print(f\"Number of scores: {len(scores_ft)} of {len(test_data)}\")\n",
        "if len(scores_ft) > 0:\n",
        "    print(f\"Average score: {sum(scores_ft)/len(scores_ft):.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ZtsVeLcVRW",
        "outputId": "3ea486d0-eac8-41d9-f08d-3ddba3c47519"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- AVALIAÇÃO DE 0 A 100 (Estilo Capítulo 7) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring model_ft_pequeno_response: 100%|██████████| 50/50 [00:15<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados para o Modelo Fine-Tuned:\n",
            "Number of scores: 50 of 50\n",
            "Average score: 78.60\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}