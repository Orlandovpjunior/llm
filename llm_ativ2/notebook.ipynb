{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f32aec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9183bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tiktoken\n",
    "from functools import partial\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "from llms_from_scratch.ch05 import generate, text_to_token_ids, token_ids_to_text\n",
    "from llms_from_scratch.ch05 import (calc_loss_loader,train_model_simple)\n",
    "from previous_chapters import plot_losses\n",
    "import time\n",
    "import re\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d2d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf=8\") as file:\n",
    "            text_data = file.read()\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(f\"Number of entries: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f028500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple entry: \n",
      "{'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exemple entry: \\n{data[50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a116083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847eaff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79acb2",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "410a1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion: train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f5d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45412c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f9a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "        batch,\n",
    "        pad_token_id=50256,\n",
    "        device=\"cuda\"\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0b185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22408f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "        batch,\n",
    "        pad_token_id = 50256,\n",
    "        device=\"cuda\"\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "661b32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "        batch,\n",
    "        pad_token_id=50256,\n",
    "        ignore_index=-100,\n",
    "        allowed_max_length=None,\n",
    "        device=\"cuda\"\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [],[]\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52cbeec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc181449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7968aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a92e051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b23c2897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23252f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination, backup_url=None):\n",
    "    def _attempt_download(download_url):\n",
    "        response = requests.get(download_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size and file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return True\n",
    "\n",
    "        block_size = 1024  # 1 KB\n",
    "        desc = os.path.basename(download_url)\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
    "            with open(destination, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=block_size):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        if _attempt_download(url):\n",
    "            return\n",
    "    except requests.exceptions.RequestException:\n",
    "        if backup_url is not None:\n",
    "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
    "            try:\n",
    "                if _attempt_download(backup_url):\n",
    "                    return\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass\n",
    "\n",
    "        error_message = (\n",
    "            f\"Failed to download from both primary URL ({url})\"\n",
    "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
    "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
    "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
    "        )\n",
    "        print(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path, backup_url)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b6d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 228kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.23MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 191kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [10:02<00:00, 2.35MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 28.3MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 1.56MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 748kiB/s] \n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dbc5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae1a9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0088384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbc5f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.825910186767578\n",
      "Validation Loss: 3.797519302368164\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader,model, device,num_batches=5\n",
    "    )\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c38d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.621\n",
      "Ep 1 (Step 000005): Train loss 1.083, Val loss 1.107\n",
      "Ep 1 (Step 000010): Train loss 0.916, Val loss 0.930\n",
      "Ep 1 (Step 000015): Train loss 0.829, Val loss 0.926\n",
      "Ep 1 (Step 000020): Train loss 0.772, Val loss 0.829\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.893\n",
      "Ep 1 (Step 000030): Train loss 0.709, Val loss 0.805\n",
      "Ep 1 (Step 000035): Train loss 0.750, Val loss 0.838\n",
      "Ep 1 (Step 000040): Train loss 0.667, Val loss 0.798\n",
      "Ep 1 (Step 000045): Train loss 0.765, Val loss 0.729\n",
      "Ep 1 (Step 000050): Train loss 0.696, Val loss 0.743\n",
      "Ep 1 (Step 000055): Train loss 0.604, Val loss 0.744\n",
      "Ep 1 (Step 000060): Train loss 0.655, Val loss 0.746\n",
      "Ep 1 (Step 000065): Train loss 0.662, Val loss 0.718\n",
      "Ep 1 (Step 000070): Train loss 0.542, Val loss 0.710\n",
      "Ep 1 (Step 000075): Train loss 0.559, Val loss 0.734\n",
      "Ep 1 (Step 000080): Train loss 0.669, Val loss 0.737\n",
      "Ep 1 (Step 000085): Train loss 0.576, Val loss 0.724\n",
      "Ep 1 (Step 000090): Train loss 0.532, Val loss 0.662\n",
      "Ep 1 (Step 000095): Train loss 0.623, Val loss 0.722\n",
      "Ep 1 (Step 000100): Train loss 0.550, Val loss 0.659\n",
      "Ep 1 (Step 000105): Train loss 0.428, Val loss 0.603\n",
      "Ep 1 (Step 000110): Train loss 0.521, Val loss 0.684\n",
      "Ep 1 (Step 000115): Train loss 0.448, Val loss 0.629\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.501, Val loss 0.643\n",
      "Ep 2 (Step 000125): Train loss 0.460, Val loss 0.662\n",
      "Ep 2 (Step 000130): Train loss 0.453, Val loss 0.665\n",
      "Ep 2 (Step 000135): Train loss 0.471, Val loss 0.627\n",
      "Ep 2 (Step 000140): Train loss 0.452, Val loss 0.707\n",
      "Ep 2 (Step 000145): Train loss 0.458, Val loss 0.730\n",
      "Ep 2 (Step 000150): Train loss 0.376, Val loss 0.660\n",
      "Ep 2 (Step 000155): Train loss 0.439, Val loss 0.648\n",
      "Ep 2 (Step 000160): Train loss 0.442, Val loss 0.670\n",
      "Ep 2 (Step 000165): Train loss 0.352, Val loss 0.676\n",
      "Ep 2 (Step 000170): Train loss 0.415, Val loss 0.677\n",
      "Ep 2 (Step 000175): Train loss 0.401, Val loss 0.651\n",
      "Ep 2 (Step 000180): Train loss 0.389, Val loss 0.693\n",
      "Ep 2 (Step 000185): Train loss 0.384, Val loss 0.673\n",
      "Ep 2 (Step 000190): Train loss 0.383, Val loss 0.649\n",
      "Ep 2 (Step 000195): Train loss 0.404, Val loss 0.639\n",
      "Ep 2 (Step 000200): Train loss 0.351, Val loss 0.592\n",
      "Ep 2 (Step 000205): Train loss 0.365, Val loss 0.647\n",
      "Ep 2 (Step 000210): Train loss 0.350, Val loss 0.626\n",
      "Ep 2 (Step 000215): Train loss 0.308, Val loss 0.644\n",
      "Ep 2 (Step 000220): Train loss 0.321, Val loss 0.621\n",
      "Ep 2 (Step 000225): Train loss 0.303, Val loss 0.599\n",
      "Ep 2 (Step 000230): Train loss 0.347, Val loss 0.653\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile. \n",
      "Training completed in 2.14 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf12b055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf9c7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83c58a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:39<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3e2d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae6f4a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d6f13fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0cc3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7153a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may be fed grains like oats, barley, or corn as a supplement to their diet. However, it's essential to provide these grains in moderation, as they can be high in calories and sugar.\n",
      "4. Fruits and vegetables: Llamas enjoy fruits and veggies as treats or snacks. Some of their favorite fruits include apples, carrots, and sweet potatoes. Leafy greens like kale, spinach, and collard greens are also a hit with llamas.\n",
      "5. Minerals: Llamas need access to minerals like calcium, phosphorus, and salt to maintain strong bones and overall health.\n",
      "\n",
      "In the wild, llamas would typically roam in herds, grazing on grasses and plants that grow in their natural habitats, such as Andean meadows or mountainous regions. In captivity, llama owners can provide a balanced diet by offering a mix of hay, grains, fruits, and vegetables, along with access to fresh water.\n",
      "\n",
      "Remember to consult with a veterinarian or experienced llama breeder to determine the best diet for your specific llama, as individual needs may vary depending on factors like age, size, and health status.\n"
     ]
    }
   ],
   "source": [
    "import requests  # noqa: F811\n",
    "# import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    # If you used OLLAMA_HOST=127.0.0.1:11435 ollama serve\n",
    "    # update the address from 11434 to 11435\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "    \"\"\"\n",
    "\n",
    "    # The book originally used the commented-out above, which is based\n",
    "    # on urllib. It works generally fine, but some readers reported\n",
    "    # issues with using urlib when using a (company) VPN.\n",
    "    # The code below uses the requests library, which doesn't seem\n",
    "    # to have these issues.\n",
    "\n",
    "    # Send the POST request\n",
    "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
    "        r.raise_for_status()\n",
    "        response_data = \"\"\n",
    "        for line in r.iter_lines(decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "            response_json = json.loads(line)\n",
    "            if \"message\" in response_json:\n",
    "                response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ecf6f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [01:13<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 47.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
